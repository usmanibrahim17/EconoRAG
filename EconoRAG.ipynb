{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "776fdfa5-a1ca-4567-9711-7b4773e62919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries and load environment variables\n",
    "import os\n",
    "import gradio as gr\n",
    "from pathlib import Path\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdace9eb-5cbc-42bb-bf7c-b8c9ba2d0374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define configuration constants and global variables\n",
    "DATA_PATH = \"dataset_1/\"\n",
    "PERSIST_DIRECTORY = \"chroma_db\"\n",
    "LLM_MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\"You are an expert chatbot specializing in comparing the economies of developing and developed countries.\n",
    "\n",
    "Use the retrieved context to cite **specific numerical data** such as GDP growth rates, FDI inflows, CO2 emissions, and similar indicators. \n",
    "\n",
    "Do NOT generalize or summarize without including data points. \n",
    "If multiple values are retrieved, compare them explicitly (e.g., \"GDP growth was 5.9% in India vs 2.1% in the USA\").\n",
    "\n",
    "Always include file names or sources when mentioning data.\"\"\"\n",
    "\n",
    "# Global variable for RAG chain\n",
    "rag_chain = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03d16906-6fed-46c3-8721-5fc0838fc30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load documents from the dataset directory\n",
    "def load_documents():\n",
    "    print(\"\\n[LOAD DOCS] Checking dataset path...\")\n",
    "    if not Path(DATA_PATH).exists():\n",
    "        raise FileNotFoundError(f\"Dataset directory '{DATA_PATH}' not found\")\n",
    "    \n",
    "    print(f\"[LOAD DOCS] Path exists. Searching for .txt files in {DATA_PATH}\")\n",
    "    loader = DirectoryLoader(DATA_PATH, glob=\"*.txt\", loader_cls=TextLoader)\n",
    "    documents = loader.load()\n",
    "    \n",
    "    if not documents:\n",
    "        raise ValueError(f\"No .txt files found in '{DATA_PATH}'\")\n",
    "    \n",
    "    print(f\"[LOAD DOCS] ✓ Successfully loaded {len(documents)} document(s)\")\n",
    "    for i, doc in enumerate(documents, 1):\n",
    "        print(f\"  - Document {i}: {doc.metadata.get('source', 'unknown')} ({len(doc.page_content)} chars)\")\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "841206d1-0e37-4d28-b4e5-8449c60a1604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to chunk documents into smaller pieces\n",
    "def chunk_documents(documents):\n",
    "    print(\"\\n[CHUNK] Starting document chunking...\")\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    chunks = splitter.split_documents(documents)\n",
    "    \n",
    "    print(f\"[CHUNK] ✓ Created {len(chunks)} chunks\")\n",
    "    total_chars = sum(len(chunk.page_content) for chunk in chunks)\n",
    "    print(f\"[CHUNK] Total characters in chunks: {total_chars}\")\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "079d55ee-65b4-4545-8b25-d46d0940366c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create and persist a vector store\n",
    "def create_vector_store(chunks):\n",
    "    print(\"\\n[EMBED] Creating embeddings and vector store...\")\n",
    "    print(\"[EMBED] Initializing OpenAI embeddings...\")\n",
    "    \n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    \n",
    "    print(f\"[EMBED] Embedding {len(chunks)} chunks into vectors...\")\n",
    "    vector_store = Chroma.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=PERSIST_DIRECTORY\n",
    "    )\n",
    "    \n",
    "    print(\"[EMBED] Persisting vector store to disk...\")\n",
    "    vector_store.persist()\n",
    "    \n",
    "    print(f\"[EMBED] ✓ Vector store created and persisted to {PERSIST_DIRECTORY}\")\n",
    "    \n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a25867eb-fd91-4cbb-a3e2-2aeb480b463a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to initialize the RAG chain\n",
    "def initialize_rag_chain():\n",
    "    global rag_chain\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"INITIALIZING RAG CHAIN\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Check if vector store exists\n",
    "    if os.path.exists(PERSIST_DIRECTORY):\n",
    "        print(f\"\\n[INIT] Found existing Chroma database at {PERSIST_DIRECTORY}\")\n",
    "        print(\"[INIT] Loading existing vector store...\")\n",
    "        vector_store = Chroma(\n",
    "            persist_directory=PERSIST_DIRECTORY,\n",
    "            embedding_function=OpenAIEmbeddings()\n",
    "        )\n",
    "        print(\"[INIT] ✓ Vector store loaded\")\n",
    "    else:\n",
    "        print(f\"\\n[INIT] No existing Chroma database found at {PERSIST_DIRECTORY}\")\n",
    "        print(\"[INIT] Creating new vector store from documents...\")\n",
    "        documents = load_documents()\n",
    "        chunks = chunk_documents(documents)\n",
    "        vector_store = create_vector_store(chunks)\n",
    "    \n",
    "    # Initialize retriever\n",
    "    print(\"\\n[RETRIEVER] Setting up retriever with k=5...\")\n",
    "    retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
    "    print(\"[RETRIEVER] ✓ Retriever initialized\")\n",
    "    \n",
    "    # Test retriever\n",
    "    print(\"\\n[TEST] Testing retriever with sample query...\")\n",
    "    test_query = \"developing countries health economic indicators\"\n",
    "    test_results = retriever.get_relevant_documents(test_query)\n",
    "    print(f\"[TEST] Query: '{test_query}'\")\n",
    "    print(f\"[TEST] ✓ Retrieved {len(test_results)} chunks\")\n",
    "    if test_results:\n",
    "        print(f\"[TEST] First chunk preview: {test_results[0].page_content[:150]}...\")\n",
    "    \n",
    "    # Initialize LLM\n",
    "    print(\"\\n[LLM] Initializing ChatOpenAI...\")\n",
    "    llm = ChatOpenAI(model=LLM_MODEL, temperature=0.3)\n",
    "    print(\"[LLM] ✓ LLM initialized\")\n",
    "    \n",
    "    # Create prompt\n",
    "    print(\"\\n[PROMPT] Creating prompt template...\")\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        f\"\"\"{SYSTEM_PROMPT}\n",
    "\n",
    "Context from documents:\n",
    "{{context}}\n",
    "\n",
    "Question: {{question}}\"\"\"\n",
    "    )\n",
    "    print(\"[PROMPT] ✓ Prompt template created\")\n",
    "    \n",
    "    # Create RAG chain\n",
    "    print(\"\\n[CHAIN] Building RAG chain...\")\n",
    "    def format_docs(docs):\n",
    "        formatted = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "        print(f\"[CHAIN] Formatted {len(docs)} documents into context ({len(formatted)} chars)\")\n",
    "        return formatted\n",
    "    \n",
    "    rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    print(\"[CHAIN] ✓ RAG chain built successfully!\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"RAG CHAIN INITIALIZATION COMPLETE\")\n",
    "    print(\"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75877772-babe-48c3-a5a5-6610fe4c2cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 6: Chat Function\n",
    "def chat(message, history):\n",
    "    try:\n",
    "        print(f\"\\n[CHAT] User query: '{message}'\")\n",
    "        # Pass message as a simple string, not a dict\n",
    "        response = rag_chain.invoke(message)\n",
    "        print(f\"[CHAT] Response generated ({len(response)} chars)\")\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error: {str(e)}\"\n",
    "        print(f\"[CHAT] ERROR: {error_msg}\")\n",
    "        return error_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "405f466c-f966-4007-abd2-b8548936d95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\chat_interface.py:347: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  self.chatbot = Chatbot(\n"
     ]
    }
   ],
   "source": [
    "# Set up the Gradio chat interface\n",
    "iface = gr.ChatInterface(\n",
    "    fn=chat,\n",
    "    title=\"Economics Chatbot: Developing vs Developed Countries\",\n",
    "    description=\"Ask me anything about the economies of developing and developed countries.\",\n",
    "    theme=gr.themes.Soft(),\n",
    "    examples=[\n",
    "        \"What are the main differences in GDP growth between developing and developed countries?\",\n",
    "        \"How do renewable energy adoption rates differ between developed and developing nations?\",\n",
    "        \"Why do developing countries have higher population growth rates?\",\n",
    "        \"What role does FDI play in economic development?\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26545f09-37ed-49ce-98e1-87a3cc389e33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "INITIALIZING RAG CHAIN\n",
      "============================================================\n",
      "\n",
      "[INIT] Found existing Chroma database at chroma_db\n",
      "[INIT] Loading existing vector store...\n",
      "[INIT] ✓ Vector store loaded\n",
      "\n",
      "[RETRIEVER] Setting up retriever with k=5...\n",
      "[RETRIEVER] ✓ Retriever initialized\n",
      "\n",
      "[TEST] Testing retriever with sample query...\n",
      "[TEST] Query: 'developing countries health economic indicators'\n",
      "[TEST] ✓ Retrieved 5 chunks\n",
      "[TEST] First chunk preview: Economic and Health Indicators: Developing vs Developed Countries (2000-2023)\n",
      "Data Overview\n",
      "This dataset contains 288 country-year observations compar...\n",
      "\n",
      "[LLM] Initializing ChatOpenAI...\n",
      "[LLM] ✓ LLM initialized\n",
      "\n",
      "[PROMPT] Creating prompt template...\n",
      "[PROMPT] ✓ Prompt template created\n",
      "\n",
      "[CHAIN] Building RAG chain...\n",
      "[CHAIN] ✓ RAG chain built successfully!\n",
      "\n",
      "============================================================\n",
      "RAG CHAIN INITIALIZATION COMPLETE\n",
      "============================================================\n",
      "\n",
      "* Running on local URL:  http://127.0.0.1:7868\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7868/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CHAT] User query: 'Why do developing countries have higher population growth rates?'\n",
      "[CHAIN] Formatted 5 documents into context (2573 chars)\n",
      "[CHAT] Response generated (1140 chars)\n",
      "\n",
      "[CHAT] User query: 'what is the Government Health Expenditure (% of GDP) of developed countries?'\n",
      "[CHAIN] Formatted 5 documents into context (3188 chars)\n",
      "[CHAT] Response generated (554 chars)\n"
     ]
    }
   ],
   "source": [
    "# Main execution block to initialize and launch the application\n",
    "if __name__ == \"__main__\":\n",
    "    initialize_rag_chain()\n",
    "    iface.launch(share=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8213a45-5568-44f9-8e3d-5e3398db58b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
